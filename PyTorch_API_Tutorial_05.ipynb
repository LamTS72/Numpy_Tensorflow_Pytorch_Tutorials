{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUTORIAL OF PYTORCH API 05 ==> CIFAR10\n",
    "## WORK WITH CONVOLUTION NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0_1_Setup GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0_2_Setup Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mnist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1_Dowload and Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:48<00:00, 3512213.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
     ]
    }
   ],
   "source": [
    "import torch.utils\n",
    "\n",
    "\n",
    "x_train = torchvision.datasets.CIFAR10(\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    root='./data/',\n",
    "    download=True\n",
    ")\n",
    "x_test = torchvision.datasets.CIFAR10(\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    root='./data/',\n",
    "    download=False\n",
    ")\n",
    "\n",
    "X_train = torch.utils.data.DataLoader(\n",
    "    dataset=x_train,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "X_test = torch.utils.data.DataLoader(\n",
    "    dataset=x_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batch_size training examples:  782\n",
      "Number of batch_size test examples:  157\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batch_size training examples: \", len(X_train))\n",
    "print(\"Number of batch_size test examples: \", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total training examples:  50048\n",
      "Number of total test examples:  10048\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total training examples: \", 64*len(X_train))\n",
    "print(\"Number of total test examples: \", 64*len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of examples in one batch:  torch.Size([64, 3, 32, 32])\n",
      "Shape of label examples in one batch:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "example = iter(X_train)\n",
    "example = next(example)\n",
    "images, labels = example\n",
    "print(\"Shape of examples in one batch: \", images.shape)\n",
    "print(\"Shape of label examples in one batch: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image shape:  torch.Size([3, 32, 32])\n",
      "One label shape:  torch.Size([])\n",
      "First label image:  tensor(4)\n",
      "First image: \n",
      " tensor([[[0.2039, 0.2588, 0.2627,  ..., 0.3294, 0.3647, 0.3882],\n",
      "         [0.2431, 0.2471, 0.2588,  ..., 0.3333, 0.3451, 0.4235],\n",
      "         [0.3020, 0.2784, 0.2784,  ..., 0.3804, 0.4157, 0.4941],\n",
      "         ...,\n",
      "         [0.5137, 0.4902, 0.4863,  ..., 0.9882, 0.9804, 0.9137],\n",
      "         [0.5451, 0.5647, 0.5137,  ..., 0.9529, 0.9451, 0.8196],\n",
      "         [0.4549, 0.4314, 0.4000,  ..., 0.6667, 0.6353, 0.5961]],\n",
      "\n",
      "        [[0.1529, 0.2078, 0.2118,  ..., 0.2745, 0.2863, 0.2980],\n",
      "         [0.1961, 0.1961, 0.2078,  ..., 0.2784, 0.2667, 0.3333],\n",
      "         [0.2549, 0.2314, 0.2314,  ..., 0.3255, 0.3333, 0.4039],\n",
      "         ...,\n",
      "         [0.3843, 0.3686, 0.3686,  ..., 0.9882, 0.9725, 0.8941],\n",
      "         [0.4235, 0.4471, 0.4118,  ..., 0.9529, 0.9373, 0.7922],\n",
      "         [0.3569, 0.3451, 0.3216,  ..., 0.6667, 0.6275, 0.5725]],\n",
      "\n",
      "        [[0.1176, 0.1725, 0.1765,  ..., 0.2000, 0.1922, 0.1961],\n",
      "         [0.1490, 0.1529, 0.1647,  ..., 0.2000, 0.1725, 0.2314],\n",
      "         [0.2000, 0.1765, 0.1765,  ..., 0.2471, 0.2431, 0.3020],\n",
      "         ...,\n",
      "         [0.2431, 0.2510, 0.2784,  ..., 0.9490, 0.9373, 0.8588],\n",
      "         [0.2902, 0.3373, 0.3176,  ..., 0.9059, 0.8941, 0.7569],\n",
      "         [0.2431, 0.2471, 0.2314,  ..., 0.6118, 0.5804, 0.5255]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"One image shape: \",images[0].shape)\n",
    "print(\"One label shape: \", labels[0].shape)\n",
    "print(\"First label image: \", labels[0])\n",
    "print(\"First image: \\n\",images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "class_names = x_train.classes\n",
    "print(len(class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_Normalize dataset(Skip Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4_Plot to visualize some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(images, class_names, labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4,4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].permute(1,2,0).numpy(), cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5_Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3, padding=0)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=32,kernel_size=3, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(in_features=6*6*32, out_features=64)\n",
    "        self.fc2 = torch.nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.flatten(out)     #can use x.view(-1, n_c*n*n)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             896\n",
      "              ReLU-2           [-1, 32, 30, 30]               0\n",
      "         MaxPool2d-3           [-1, 32, 15, 15]               0\n",
      "            Conv2d-4           [-1, 32, 13, 13]           9,248\n",
      "              ReLU-5           [-1, 32, 13, 13]               0\n",
      "         MaxPool2d-6             [-1, 32, 6, 6]               0\n",
      "           Flatten-7                 [-1, 1152]               0\n",
      "            Linear-8                   [-1, 64]          73,792\n",
      "              ReLU-9                   [-1, 64]               0\n",
      "           Linear-10                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 84,586\n",
      "Trainable params: 84,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.60\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 0.93\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ConvolutionNN().to(device)\n",
    "print(summary(model, (3,32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6_Select Hyperparameters for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "n_steps = len(X_train)\n",
    "n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(X_train):\n",
    "        model.train()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #forward training\n",
    "        outputs = model(images)\n",
    "        loss = losses(outputs, labels)\n",
    "\n",
    "        #backward training\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if(i+1) % 100 == 0:\n",
    "            print(f\"epoch {epoch+1} / {epochs}, step {i} / {n_steps}, loss = {loss.item():.4f}\")\n",
    "print(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7_Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model:  61.93\n",
      "Accuracy of Class [0]: 62.6\n",
      "Accuracy of Class [1]: 74.4\n",
      "Accuracy of Class [2]: 63.9\n",
      "Accuracy of Class [3]: 44.0\n",
      "Accuracy of Class [4]: 39.8\n",
      "Accuracy of Class [5]: 52.5\n",
      "Accuracy of Class [6]: 78.6\n",
      "Accuracy of Class [7]: 64.1\n",
      "Accuracy of Class [8]: 82.6\n",
      "Accuracy of Class [9]: 56.8\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(class_names))]\n",
    "    n_class_sample = [0 for i in range(len(class_names))]\n",
    "    for i, (images, labels) in enumerate(X_test):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        #print(f\"Prediction at batch {i}-th {predictions}\")\n",
    "        n_samples += len(labels)\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        if len(labels) == 64:\n",
    "            for j in range(batch_size):\n",
    "                label = labels[j]\n",
    "                pred = predictions[j]\n",
    "                if(pred == label):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_sample[label] += 1\n",
    "        else:\n",
    "            for j in range(len(labels)):\n",
    "                label = labels[j]\n",
    "                pred = predictions[j]\n",
    "                if(pred == label):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_sample[label] += 1\n",
    "accuracy = 100*n_correct / n_samples\n",
    "print(\"Accuracy of Model: \", accuracy)\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    accuracy = 100*n_class_correct[i] / n_class_sample[i]\n",
    "    print(f\"Accuracy of Class [{i}]: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
