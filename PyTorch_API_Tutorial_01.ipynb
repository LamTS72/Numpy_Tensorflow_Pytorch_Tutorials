{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL OF PYTORCH API 01 ==> STEP BY STEPS MANUALLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1_Step by Steps Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 4., 5.])\n",
      "tensor([10., 20., 30., 50.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,4,5], dtype=torch.float32)\n",
    "y = torch.tensor([10,20,30,50], dtype=torch.float32)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2189], requires_grad=True)\n",
      "tensor([0.1721], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.rand(1,dtype=torch.float32, requires_grad=True)\n",
    "b = torch.rand(1,dtype=torch.float32, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w*x + b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    return ((y_hat - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before of forward(5) tensor([1.2664], grad_fn=<AddBackward0>)\n",
      "epoch 0, w= 2.258, b=0.706,loss = 920.38189697\n",
      "epoch 10, w= 8.153, b=2.191,loss = 20.14499092\n",
      "epoch 20, w= 8.522, b=2.213,loss = 16.90930939\n",
      "epoch 30, w= 8.561, b=2.150,loss = 16.84736443\n",
      "epoch 40, w= 8.579, b=2.084,loss = 16.80057907\n",
      "epoch 50, w= 8.596, b=2.021,loss = 16.75749207\n",
      "epoch 60, w= 8.612, b=1.960,loss = 16.71777725\n",
      "epoch 70, w= 8.628, b=1.902,loss = 16.68116951\n",
      "epoch 80, w= 8.643, b=1.846,loss = 16.64742661\n",
      "epoch 90, w= 8.657, b=1.792,loss = 16.61632538\n",
      "Prediction after of forward(5) tensor([45.0917], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction before of forward(5) \" + str(forward(5)))\n",
    "n_iters = 100\n",
    "learning_rate = 0.01\n",
    "for epoch in range(n_iters):\n",
    "    #forward\n",
    "    y_hat = forward(x)\n",
    "\n",
    "    #cost value\n",
    "    l = loss(y,y_hat)\n",
    "\n",
    "    #gradients\n",
    "    l.backward()\n",
    "\n",
    "    #update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch}, w= {w.item():.3f}, b={b.item():.3f},loss = {l.item():.8f}')\n",
    "    \n",
    "print(\"Prediction after of forward(5) \" + str(forward(5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 4., 5.])\n",
      "tensor([10., 20., 30., 50.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,4,5], dtype=torch.float32)\n",
    "y = torch.tensor([10,20,30,50], dtype=torch.float32)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3816], requires_grad=True)\n",
      "tensor([0.9219], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.rand(1,dtype=torch.float32, requires_grad=True)\n",
    "b = torch.rand(1,dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction befor of forward(5) tensor([2.8299], grad_fn=<AddBackward0>)\n",
      "epoch 0, w= 2.339, b= 0.922, loss = 848.79644775\n",
      "epoch 10, w= 8.410, b= 0.922, loss = 20.75762367\n",
      "epoch 20, w= 8.855, b= 0.922, loss = 16.31268883\n",
      "epoch 30, w= 8.887, b= 0.922, loss = 16.28882790\n",
      "epoch 40, w= 8.890, b= 0.922, loss = 16.28869820\n",
      "epoch 50, w= 8.890, b= 0.922, loss = 16.28870010\n",
      "epoch 60, w= 8.890, b= 0.922, loss = 16.28869438\n",
      "epoch 70, w= 8.890, b= 0.922, loss = 16.28869438\n",
      "epoch 80, w= 8.890, b= 0.922, loss = 16.28869438\n",
      "epoch 90, w= 8.890, b= 0.922, loss = 16.28869438\n",
      "Prediction after of forward(5) tensor([45.3716], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction befor of forward(5) \" + str(forward(5)))\n",
    "n_iters = 100\n",
    "learning_rate = 0.01\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "for epoch in range(n_iters):\n",
    "    #forward\n",
    "    y_hat = forward(x)\n",
    "\n",
    "    #cost value\n",
    "    l = loss(y, y_hat)\n",
    "\n",
    "    #gradients\n",
    "    l.backward()\n",
    "\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch}, w= {w.item():.3f}, b= {b.item():.3f}, loss = {l.item():.8f}')\n",
    "    \n",
    "print(\"Prediction after of forward(5) \" + str(forward(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "tensor([[10.],\n",
      "        [20.],\n",
      "        [30.],\n",
      "        [50.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1],[2],[4],[5]], dtype=torch.float32)\n",
    "y = torch.tensor([[10],[20],[30],[50]], dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(in_features=1,out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before of model(x_test)= -1.5939687490463257\n",
      "epoch 0, w= 1.739, b= 1.105,loss = 1035.93347168\n",
      "epoch 10, w= 8.003, b= 2.667,loss = 20.98074150\n",
      "epoch 20, w= 8.397, b= 2.675,loss = 17.30628204\n",
      "epoch 30, w= 8.443, b= 2.593,loss = 17.21194839\n",
      "epoch 40, w= 8.466, b= 2.510,loss = 17.13663101\n",
      "epoch 50, w= 8.487, b= 2.430,loss = 17.06724739\n",
      "epoch 60, w= 8.508, b= 2.353,loss = 17.00328827\n",
      "epoch 70, w= 8.528, b= 2.279,loss = 16.94433784\n",
      "epoch 80, w= 8.546, b= 2.208,loss = 16.89001846\n",
      "epoch 90, w= 8.565, b= 2.140,loss = 16.83991432\n",
      "Prediction after of model(x_test)= 44.981834411621094\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction before of model(x_test)= \" + str(model(x_test).item()))\n",
    "n_iters = 100\n",
    "learning_rate = 0.01\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(n_iters):\n",
    "    #forward\n",
    "    y_hat = model(x)\n",
    "\n",
    "    #cost value\n",
    "    l = loss(y, y_hat)\n",
    "\n",
    "    #gradients\n",
    "    l.backward()\n",
    "\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch}, w= {w.item():.3f}, b= {b.item():.3f},loss = {l.item():.8f}')\n",
    "    \n",
    "print(\"Prediction after of model(x_test)= \" + str(model(x_test).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4_Advanced with Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before of model(x_test)= -2.6253533363342285\n",
      "epoch 0, w= 1.742, b= 0.365,loss = 1091.44384766\n",
      "epoch 10, w= 8.168, b= 2.000,loss = 20.61393356\n",
      "epoch 20, w= 8.566, b= 2.037,loss = 16.78608704\n",
      "epoch 30, w= 8.605, b= 1.981,loss = 16.73181343\n",
      "epoch 40, w= 8.622, b= 1.923,loss = 16.69406509\n",
      "epoch 50, w= 8.637, b= 1.866,loss = 16.65931320\n",
      "epoch 60, w= 8.652, b= 1.811,loss = 16.62728500\n",
      "epoch 70, w= 8.666, b= 1.759,loss = 16.59775734\n",
      "epoch 80, w= 8.679, b= 1.709,loss = 16.57054520\n",
      "epoch 90, w= 8.692, b= 1.660,loss = 16.54546165\n",
      "Prediction after of model(x_test)= 45.133296966552734\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(input_dim=1, output_dim=1)\n",
    "print(\"Prediction before of model(x_test)= \" + str(model(x_test).item()))\n",
    "n_iters = 100\n",
    "learning_rate = 0.01\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(n_iters):\n",
    "    #forward\n",
    "    y_hat = model(x)\n",
    "\n",
    "    #cost value\n",
    "    l = loss(y, y_hat)\n",
    "\n",
    "    #gradients\n",
    "    l.backward()\n",
    "\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch}, w= {w.item():.3f}, b= {b.item():.3f},loss = {l.item():.8f}')\n",
    "    \n",
    "print(\"Prediction after of model(x_test)= \" + str(model(x_test).item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
