{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "'''ADD MORE IF NEEDED'''\n",
    "from torch.nn import Module, Linear, ReLU, Conv2d, Sequential , CrossEntropyLoss\n",
    "from  torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize \n",
    "''''''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ADD THE PATH TO VIEW IN TENSORBOARD\n",
    "'''\n",
    "PATH = \"\"\n",
    "writer = SummaryWriter('runs/' + PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ClassModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "            CHANGE TO APPLY (here 28*28 use for example MNIST)\n",
    "        '''\n",
    "        super(ClassModel, self).__init__()\n",
    "        self.L1 = Linear(in_features=28*28, out_features=256) \n",
    "        self.L2 = Linear(in_features=256, out_features=128)\n",
    "        self.L3 = Linear(in_features=128, out_features=64)\n",
    "        self.L4 = Linear(in_features=64, out_features=10)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "        '''\n",
    "            NOT CHANGE HERE\n",
    "        '''\n",
    "        # self.train_dataset = None \n",
    "        # self.val_dataset = None \n",
    "        # self.test_dataset = None\n",
    "        # self.optimizer= None \n",
    "        # self.step_lr_scheduler = None\n",
    "        # self.losses = None\n",
    "        # self.checkpoint = None\n",
    "        self.outputs_train = []\n",
    "        self.outputs_val = []\n",
    "        self.outputs_test = []\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        CHANGE TO APPLY\n",
    "        '''\n",
    "        x = self.L1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.L2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.L3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.L4(x)\n",
    "        return x\n",
    "    \n",
    "    def prepare_data(self,percentage_val = 0.2):\n",
    "        '''\n",
    "            CHANGE TO APPLY\n",
    "        '''\n",
    "        name_dataset = torchvision.datasets.MNIST\n",
    "        train_dataset_full = name_dataset(\n",
    "            train=True,\n",
    "            transform=Compose([ToTensor()]),\n",
    "            root='./data/',\n",
    "            download=True,\n",
    "        )\n",
    "        self.test_dataset = name_dataset(\n",
    "            train=False,\n",
    "            transform=Compose([ToTensor()]),\n",
    "            root='./data/',\n",
    "            download=False,\n",
    "        )\n",
    "        \n",
    "        train_size = int((1.0-percentage_val)*len(train_dataset_full))\n",
    "        val_size = int(percentage_val*len(train_dataset_full))\n",
    "        self.train_dataset, self.val_dataset = random_split(train_dataset_full, lengths=[train_size,val_size])      \n",
    "        return self.train_dataset, self.val_dataset, self.test_dataset\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        '''\n",
    "            CHANGE BATCH_SIZE TO APPLY\n",
    "        '''\n",
    "        train_dataset = DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        return train_dataset\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        '''\n",
    "            CHANGE BATCH_SIZE TO APPLY\n",
    "        '''\n",
    "        val_dataset = DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        return val_dataset\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        '''\n",
    "            CHANGE BATCH_SIZE TO APPLY\n",
    "        '''\n",
    "        test_dataset = DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        return test_dataset\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        '''\n",
    "            CHANGE LEARNING_RATE, LOSS_ENTROPY,CLASS LR_SCHEDULER(step_size == epoch) TO APPLY\n",
    "        '''\n",
    "        learning_rate = 0.001\n",
    "        optimizer = Adam(self.parameters(), lr=learning_rate)\n",
    "        #self.losses = CrossEntropyLoss()\n",
    "        #step_lr_scheduler = lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)\n",
    "        return optimizer#{\"optimizers\": optimizer, \"lr_scheduler\": step_lr_scheduler}#, self.losses\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        data = data.reshape(-1,28*28).to(device)\n",
    "        target = target.to(device)\n",
    "        output = self(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        accuracy = torch.sum(predictions == target).item()\n",
    "        self.outputs_train.append(predictions)\n",
    "        return {\"loss\":loss, \"correct\":accuracy}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        data = data.reshape(-1, 28*28).to(device)\n",
    "        target = target.to(device)\n",
    "        output = self(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        accuracy = torch.sum(predictions == target).item()\n",
    "        self.outputs_val.append(predictions)\n",
    "        return {\"val_loss\":loss, \"correct\":accuracy}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        data = data.reshape(-1, 28*28).to(device)\n",
    "        target = target.to(device)\n",
    "        output = self(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        accuracy = torch.sum(predictions == target).item()\n",
    "        self.outputs_test.append(predictions)\n",
    "        return {\"test_loss\":loss, \"correct\":accuracy}\n",
    "        \n",
    "    # def on_train_epoch_end(self):\n",
    "    #     # avg_loss = torch.stack([x['loss'] for x in self.outputs_train]).mean()\n",
    "    #     # avg_correct = torch.stack([x['correct'] for x in self.outputs_train]).mean()\n",
    "    #     all_correct = torch.stack(self.outputs_train)\n",
    "    #     self.outputs_train.clear()\n",
    "    #     return all_correct#{\"avg_train_loss\": avg_loss, \"avg_correct\": avg_correct}\n",
    "    \n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     # avg_loss = torch.stack([x['val_loss'] for x in self.outputs_val]).mean()\n",
    "    #     # avg_correct = torch.stack([x['correct'] for x in self.outputs_val]).mean()\n",
    "    #     all_correct = torch.stack(self.outputs_val)\n",
    "    #     self.outputs_val.clear()\n",
    "    #     return all_correct#{\"avg_val_loss\": avg_loss, \"avg_correct\": avg_correct}\n",
    "    \n",
    "    # def on_test_epoch_end(self):\n",
    "    #     # avg_loss = torch.stack([x['test_loss'] for x in self.outputs_test]).mean()\n",
    "    #     # avg_correct = torch.stack([x['correct'] for x in self.outputs_test]).mean()\n",
    "    #     all_correct = torch.stack(self.outputs_test)\n",
    "    #     self.outputs_test.clear()\n",
    "    #     return all_correct#{\"avg_test_loss\": avg_loss, \"avg_correct\": avg_correct}\n",
    "\n",
    "    # def save_model(self, PATH):\n",
    "    #     return torch.save(self.state_dict(), PATH)\n",
    "    \n",
    "    # def load_state_dict(self, PATH):\n",
    "    #     return self.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    # def take_checkpoint(self, epoch, loss, PATH):\n",
    "    #     self.checkpoint ={\n",
    "    #         'epoch': epoch,\n",
    "    #         'model_state_dict': self.state_dict(),\n",
    "    #         'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "    #         'loss': loss\n",
    "    #     }\n",
    "    #     return torch.save(self.checkpoint, PATH)\n",
    "    \n",
    "    # def load_checkpoint(self, PATH):\n",
    "    #     self.checkpoint = torch.load(PATH)\n",
    "    #     self.load_state_dict(self.checkpoint['model_state_dict'])\n",
    "    #     self.optimizer.load_state_dict(self.checkpoint['optimizer_state_dict'])\n",
    "    #     epoch = self.checkpoint['epoch']\n",
    "    #     loss = self.checkpoint['loss']\n",
    "    #     return epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | L1   | Linear | 200 K  | train\n",
      "1 | L2   | Linear | 32.9 K | train\n",
      "2 | L3   | Linear | 8.3 K  | train\n",
      "3 | L4   | Linear | 650    | train\n",
      "4 | relu | ReLU   | 0      | train\n",
      "----------------------------------------\n",
      "242 K     Trainable params\n",
      "0         Non-trainable params\n",
      "242 K     Total params\n",
      "0.971     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790c88cc7af24a1f8eae35336571ecac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37573a74abf745d986d082aa4a6575dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbf1c63509148bc993bd2a11ae5896d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcbb0c17bed4aae86ef44bf98b84036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Restoring states from the checkpoint path at /Users/chessman/Desktop/ML_DL/Code_Tutorials/Numpy_Tensorflow_Pytorch_Tutorials/lightning_logs/version_1/checkpoints/epoch=1-step=1500.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/chessman/Desktop/ML_DL/Code_Tutorials/Numpy_Tensorflow_Pytorch_Tutorials/lightning_logs/version_1/checkpoints/epoch=1-step=1500.ckpt\n",
      "/Users/chessman/miniforge3/envs/PyJupyter/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f130c8d4fc4e138020eaa910c8eb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassModel()\n",
    "trainer = pl.Trainer(max_epochs=2, fast_dev_run=False, accelerator=\"cpu\")\n",
    "trainer.fit(model)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
